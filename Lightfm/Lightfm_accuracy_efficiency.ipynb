{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "saving-particle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grand-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "concrete-tribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.8/site-packages/distributed/node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 45131 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918257ed8c064df8866309bc7d3e07f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>SLURMCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.32.33.10:44205</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.32.33.10:45131/status' target='_blank'>http://10.32.33.10:45131/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.32.33.10:44205' processes=0 threads=0, memory=0 B>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOCAL = False\n",
    "\n",
    "if LOCAL:\n",
    "    # This line creates a single-machine dask client\n",
    "    client = Client()\n",
    "else:    \n",
    "    # This line creates a SLURM cluster dask and dask client\n",
    "    # Logging outputs will be stored in /scratch/{your-netid}\n",
    "    \n",
    "    cluster = SLURMCluster(memory='4GB', cores=2, python='/scratch/work/public/dask/bin/python', \n",
    "                               local_directory='/tmp/{}/'.format(os.environ['SLURM_JOB_USER']),\n",
    "                               job_extra=['--output=/scratch/{}/slurm-%j.out'.format(os.environ['SLURM_JOB_USER'])])\n",
    "\n",
    "    cluster.submit_command = 'slurm'\n",
    "    cluster.scale(100)\n",
    "\n",
    "    display(cluster)\n",
    "    client = Client(cluster)\n",
    "\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "weighted-richmond",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in train and test dataset to calculate accuracy\n",
    "#train_test = dd.read_csv(\"../train_test_small.csv\")\n",
    "#test_modified = dd.read_csv(\"../test_modified_small.csv\")\n",
    "train_test = dd.read_csv(\"../train_test_large.csv\")\n",
    "test_modified = dd.read_csv(\"../test_modified_large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "alternate-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "#partition the dataframe\n",
    "train_test = train_test.repartition(npartitions=100)\n",
    "test_modified = test_modified.repartition(npartitions=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "noble-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify data to input into lightfm dataset\n",
    "train = train_test[['userId', 'movieId', 'rating']]\n",
    "train_bag = train.to_bag()\n",
    "train_movie = train['movieId']\n",
    "train_user = train['userId']\n",
    "train_movie_bag = train_movie.to_bag()\n",
    "train_user_bag = train_user.to_bag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "significant-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify data to input into lightfm dataset\n",
    "test = test_modified[['userId', 'movieId', 'rating']]\n",
    "test_bag = test.to_bag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "intermediate-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lightfm dataset\n",
    "train_dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fluid-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit dataset\n",
    "train_dataset.fit(train_user_bag, train_movie_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "constant-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build train interactions\n",
    "(train_interactions, train_weights) = train_dataset.build_interactions(train_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "human-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build test interactions\n",
    "(test_interactions, test_weights) = train_dataset.build_interactions(test_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "pressing-honey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<137109x35232 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 8363468 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the size of the interactions\n",
    "train_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tropical-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model with tuned parameters\n",
    "#small_model = LightFM(loss='warp', no_components=10, item_alpha=0.02, user_alpha=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "alternate-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_model = LightFM(loss='warp', no_components=50, item_alpha=0.05, user_alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "seventh-utility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 311 ms, sys: 6.71 ms, total: 318 ms\n",
      "Wall time: 331 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x14897656b5e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "#%time small_model.fit(train_weights, epochs=20, num_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "interesting-constitution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 40s, sys: 4.02 s, total: 6min 44s\n",
      "Wall time: 7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x14893568c100>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time large_model.fit(train_weights, epochs=20, num_threads=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "minimal-empire",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create predicted rank based on existing test interactions\n",
    "small_ranks = small_model.predict_rank(test_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fantastic-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer sparse matrix to array\n",
    "small_ranks_array = small_ranks.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cooperative-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average precision for every user\n",
    "precision = list()\n",
    "for i in range(len(small_ranks_array)):\n",
    "    ranks_i = small_ranks_array[i][small_ranks_array[i]!=0]\n",
    "    ranks_i.sort()\n",
    "    count = 0\n",
    "    precision_i = 0\n",
    "    for rank in ranks_i:\n",
    "        count += 1\n",
    "        precision_i += count/rank\n",
    "        if rank > 100:\n",
    "            break\n",
    "    if count==0:\n",
    "        precision.append(0)\n",
    "    else:\n",
    "        precision.append(precision_i/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "outdoor-robert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP of the small dataset is 0.182347329892548\n"
     ]
    }
   ],
   "source": [
    "print('MAP of the small dataset is', np.mean(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "modified-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and save predicted rank matrix\n",
    "#large_ranks = large_model.predict_rank(test_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "green-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp.save_npz(\"large_ranks.npz\", large_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-navigator",
   "metadata": {},
   "source": [
    "Transfering large sparse matrix to array kills the kernel. Therefore, we save the ranks matrix and compute MAP in the local machine. Please see the MAP_large.ipynb for reference. Overall, we have a MAP of 0.112 for the large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aquatic-destination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision at 10 of the small dataset is 0.10931146\n"
     ]
    }
   ],
   "source": [
    "print(\"precision at 10 of the small dataset is\", precision_at_k(small_model, test_interactions, k=100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "chinese-detector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision at 10 of the large dataset is 0.06818348\n"
     ]
    }
   ],
   "source": [
    "print(\"precision at 10 of the large dataset is\", precision_at_k(large_model, test_interactions, k=100).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-customs",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
